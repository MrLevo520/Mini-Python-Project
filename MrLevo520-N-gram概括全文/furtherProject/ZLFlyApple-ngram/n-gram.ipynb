{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模块测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'cj!/n']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "list = [',,a,','b!','cj!/n']\n",
    "item = []\n",
    "for i in list:\n",
    "    i = i.strip(string.punctuation)\n",
    "    #在循环体中用item.strip(string.punctuation) 对内容中的所有单词进行清洗，单词两端\n",
    "    #的任何标点符号都会被去掉，但带连字符的单词（连字符在单词内部）仍然会保留。\n",
    "    item.append(i)\n",
    "print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('name1', '2'), ('name2', '1'), ('name3', '2')]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "dict_ = {'name1':'2','name2':'1','name3':'2'}\n",
    "print(sorted(dict_.items(),key=operator.itemgetter(0,1),reverse=False))#排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "\n",
    "def isCommon(ngram):\n",
    "    commonWords = [\"the\", \"be\", \"and\", \"of\", \"a\", \"in\", \"to\", \"have\", \"it\",\n",
    "        \"i\", \"that\", \"for\", \"you\", \"he\", \"with\", \"on\", \"do\", \"say\", \"this\",\n",
    "        \"they\", \"is\", \"an\", \"at\", \"but\",\"we\", \"his\", \"from\", \"that\", \"not\",\n",
    "        \"by\", \"she\", \"or\", \"as\", \"what\", \"go\", \"their\",\"can\", \"who\", \"get\",\n",
    "        \"if\", \"would\", \"her\", \"all\", \"my\", \"make\", \"about\", \"know\", \"will\",\n",
    "        \"as\", \"up\", \"one\", \"time\", \"has\", \"been\", \"there\", \"year\", \"so\",\n",
    "        \"think\", \"when\", \"which\", \"them\", \"some\", \"me\", \"people\", \"take\",\n",
    "        \"out\", \"into\", \"just\", \"see\", \"him\", \"your\", \"come\", \"could\", \"now\",\n",
    "        \"than\", \"like\", \"other\", \"how\", \"then\", \"its\", \"our\", \"two\", \"more\",\n",
    "        \"these\", \"want\", \"way\", \"look\", \"first\", \"also\", \"new\", \"because\",\n",
    "        \"day\", \"more\", \"use\", \"no\", \"man\", \"find\", \"here\", \"thing\", \"give\",\n",
    "        #\"laughter\", \"applause\", \n",
    "        \"many\", \"well\", \"said\", \"was\", \"are\", \"were\", \"had\"]\n",
    "    #############################################\n",
    "    for word in ngram:\n",
    "        if word in commonWords:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cleanInput(input):\n",
    "    \n",
    "    input = re.sub('\\n+', \" \", input).lower()\n",
    "    input = re.sub('\\[[0-9]*\\]', \"\", input)\n",
    "    input = re.sub(' +', \" \", input)\n",
    "    input = bytes(input, \"UTF-8\")\n",
    "    input = input.decode(\"ascii\", \"ignore\")\n",
    "    \n",
    "    cleanInput = []\n",
    "    input = input.split(' ')\n",
    "    for item in input:\n",
    "        item = item.strip(string.punctuation)\n",
    "        if len(item) > 1 or (item.lower() == 'a' or item.lower() == 'i'):\n",
    "            cleanInput.append(item)\n",
    "    return cleanInput\n",
    "\n",
    "def ngrams(input, n):\n",
    "    input = cleanInput(input)\n",
    "    print(\"Total words: %d\"%len(input))\n",
    "    output = {}\n",
    "    for i in range(len(input)-n+1):\n",
    "        ngramTemp = \" \".join(input[i:i+n])\n",
    "        #print(ngramTemp)\n",
    "        if isCommon(ngramTemp.split()):\n",
    "            #print(\"in\")\n",
    "            pass\n",
    "        else:\n",
    "            if ngramTemp not in output:\n",
    "                output[ngramTemp] = 0\n",
    "            output[ngramTemp] += 1\n",
    "    return (output,len(input))\n",
    "\n",
    "#content = str(\n",
    "#    urlopen(\"http://pythonscraping.com/files/inaugurationSpeech.txt\").read(),\n",
    "#    'utf-8')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "Total words: 2232\n",
      "laughter 61 36\n",
      "applause 26 85\n",
      "2014\n",
      "Total words: 2096\n",
      "laughter 60 34\n",
      "applause 22 95\n",
      "2015\n",
      "Total words: 2302\n",
      "laughter 79 29\n",
      "applause 32 71\n",
      "2016\n",
      "Total words: 2809\n",
      "laughter 99 28\n",
      "applause 52 54\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    year = 2013+i\n",
    "    print(year)\n",
    "    content=open(\"Obama's dinner speech %d.txt\"%year).read()\n",
    "    (ngram,length)=(ngrams(content, 1))\n",
    "    sortedNGrams = sorted(ngram.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    ngram.clear()\n",
    "    for top2 in range(2):\n",
    "        print(sortedNGrams[top2][0],sortedNGrams[top2][1],length//sortedNGrams[top2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "Total words: 2232\n",
      "('white house', 4)\n",
      "('house correspondents', 3)\n",
      "('charm offensive', 3)\n",
      "('groucho marx', 3)\n",
      "2014\n",
      "Total words: 2096\n",
      "('white house', 4)\n",
      "('house correspondents', 4)\n",
      "('correspondents association', 4)\n",
      "2015\n",
      "Total words: 2302\n",
      "('white house', 5)\n",
      "('ted cruz', 5)\n",
      "('house correspondents', 4)\n",
      "('jeb bush', 3)\n",
      "('weve got', 3)\n",
      "('anger translator', 3)\n",
      "2016\n",
      "Total words: 2809\n",
      "('white house', 7)\n",
      "('free press', 5)\n",
      "('little bit', 4)\n",
      "('house correspondents', 3)\n",
      "('correspondents dinner', 3)\n",
      "('press corps', 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    year = 2013+i\n",
    "    print(year)\n",
    "    content=open(\"Obama's dinner speech %d.txt\"%year).read()\n",
    "    ngram=(ngrams(content, 2))\n",
    "    sortedNGrams = sorted(ngram.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    ngram.clear()\n",
    "    for top2 in range(20):\n",
    "        if sortedNGrams[top2][1]>2:\n",
    "        #print(type(sortedNGrams[top2]))\n",
    "            print(sortedNGrams[top2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
